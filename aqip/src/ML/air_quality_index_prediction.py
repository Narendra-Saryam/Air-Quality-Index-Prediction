# -*- coding: utf-8 -*-
"""Air Quality Index Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SWTeAFhx01gi5fuG_0zgWI3nYihSGhCo
"""

# List of 100+ major Indian cities (predefined)
MAJOR_CITIES = [
    "Delhi", "Mumbai", "Bengaluru", "Hyderabad", "Ahmedabad",
    "Chennai", "Kolkata", "Surat", "Pune", "Jaipur", "Lucknow",
    "Kanpur", "Nagpur", "Visakhapatnam", "Indore", "Thane", "Bhopal",
    "Patna", "Vadodara", "Ghaziabad", "Ludhiana", "Coimbatore", "Agra",
    "Madurai", "Nashik", "Faridabad", "Meerut", "Rajkot", "Varanasi",
    "Srinagar", "Aurangabad", "Dhanbad", "Amritsar", "Allahabad", "Ranchi",
    "Jabalpur", "Gwalior", "Jodhpur", "Raipur", "Kota",
    "Guwahati", "Chandigarh", "Solapur", "Hubli", "Mysore", "Tiruchirappalli",
    "Bareilly", "Aligarh", "Bhubaneswar", "Salem", "Warangal", "Guntur",
    "Bhiwandi", "Saharanpur", "Gorakhpur", "Bikaner", "Amravati", "Noida",
    "Jamshedpur", "Bhilai", "Cuttack", "Firozabad", "Kochi", "Goa", "Shimla",
    "Dehradun", "Chandigarh", "Gurgaon", "Navi Mumbai", "Noida", "Thiruvananthapuram",
    "Mangalore", "Jalandhar", "Tirunelveli", "Udaipur", "Malappuram",
    "Durgapur", "Ajmer", "Erode", "Nellore", "Kurnool", "Belgaum", "Jamnagar",
    "Tirupati", "Ujjain", "Davangere", "Jalgaon", "Akola", "Karnal", "Bokaro",
    "Bhagalpur", "Latur", "Hosur", "Barasat", "Ambattur", "Bihar Sharif", "Panipat",
    "Kharagpur", "Tumkur", "Shivamogga", "Rohtak","Sonipat"
]

import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta

# API Configuration (replace with your key)
API_KEY = "c23cd2d157876f5f22de2f38609386099a2bcae6"
CITIES = ["Delhi", "Mumbai", "Bengaluru", "Hyderabad", "Chennai", "Kolkata"]

def fetch_real_time_aqi(city):
    """Fetch real-time AQI and pollutants for a city using WAQI API."""
    try:
        url = f"https://api.waqi.info/feed/{city}/?token={API_KEY}"
        response = requests.get(url)
        data = response.json()
        if data['status'] == 'ok':
            aqi = data['data']['aqi']
            pollutants = data['data']['iaqi']
            return aqi, pollutants
        return None, None
    except Exception as e:
        print(f"Error fetching data for {city}: {e}")
        return None, None

def generate_synthetic_history(city, base_aqi, start_date, end_date):
    """Generate synthetic historical AQI data with trends and seasonality."""
    date_range = pd.date_range(start=start_date, end=end_date, freq='D')
    data = []
    for date in date_range:
        # Seasonal effect (higher pollution in winter)
        month = date.month
        if month in [11, 12, 1]:
            seasonal_effect = np.random.normal(40, 10)
        elif month in [4, 5, 6]:
            seasonal_effect = np.random.normal(20, 5)
        else:
            seasonal_effect = np.random.normal(0, 5)

        # Long-term trend (adjust based on city)
        year = date.year
        trend = 0.3 * (year - 2013)  # Customize per city

        # Noise and final AQI
        noise = np.random.normal(0, 15)
        synthetic_aqi = base_aqi + seasonal_effect + trend + noise
        synthetic_aqi = max(0, synthetic_aqi)

        data.append({
            "City": city,
            "Date": date.strftime("%Y-%m-%d"),
            "AQI": round(synthetic_aqi, 1),
            "Source": "Synthetic"
        })
    return data

# Generate dataset
all_data = []
start_date = datetime.now() - timedelta(days=365*10)
end_date = datetime.now()

for city in CITIES:
    # Fetch real-time AQI to anchor synthetic data
    real_aqi, pollutants = fetch_real_time_aqi(city)
    base_aqi = real_aqi if real_aqi else np.random.randint(80, 200)  # Fallback

    # Generate synthetic history
    synthetic_history = generate_synthetic_history(city, base_aqi, start_date, end_date)
    all_data.extend(synthetic_history)

    # Add real-time data (today's date)
    if real_aqi:
        all_data.append({
            "City": city,
            "Date": datetime.now().strftime("%Y-%m-%d"),
            "AQI": real_aqi,
            "Source": "WAQI API",
            "Pollutants": pollutants
        })

# Create DataFrame and save
df = pd.DataFrame(all_data)
df.to_csv("hybrid_aqi_india_10years.csv", index=False)
print("Dataset generated with hybrid data!")

# from google.colab import files
# files.download('historical_aqi_data.csv')

# !wget -qO- https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh | bash -

# !conda install -n base -c conda-forge ipykernel -y

# !conda install -c conda-forge fbprophet -y

import pandas as pd
from prophet import Prophet
import matplotlib.pyplot as plt

def train_prophet_model(city_name, periods=30):
    # Load historical data
    df = pd.read_csv('hybrid_aqi_india_10years.csv')
    city_df = df[df['City'] == city_name][['Date', 'AQI']]

    # Prepare data format
    city_df = city_df.rename(columns={'Date': 'ds', 'AQI': 'y'})
    city_df['ds'] = pd.to_datetime(city_df['ds'])
    city_df = city_df.dropna()

    # Check if enough data is available for training
    if len(city_df) < 2:
        print(f"Insufficient data for {city_name}. Need at least 2 data points for training.")
        return None, None  # Return None if not enough data

    # Split data
    train_size = int(len(city_df) * 0.8)
    train, test = city_df.iloc[:train_size], city_df.iloc[train_size:]

    # Train model
    model = Prophet(seasonality_mode='multiplicative', yearly_seasonality=True)
    model.fit(train)

    # Make predictions
    future = model.make_future_dataframe(periods=periods, freq='D')
    forecast = model.predict(future)

    # Visualize
    fig = model.plot(forecast)
    plt.title(f'AQI Forecast for {city_name}')
    plt.show()

    return model, forecast

# Example usage
model, forecast = train_prophet_model('Delhi', periods=365)

# Next day prediction
_, day_forecast = train_prophet_model('Mumbai', periods=1)

# Weekly forecast
_, week_forecast = train_prophet_model('Bengaluru', periods=7)

# Monthly forecast
_, month_forecast = train_prophet_model('Kolkata', periods=30)

# Yearly forecast (requires sufficient historical data)
_, year_forecast = train_prophet_model('Chennai', periods=365)